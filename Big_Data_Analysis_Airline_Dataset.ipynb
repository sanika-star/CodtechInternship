{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task : 1 BIG DATA ANALYSIS\n",
        "Data Analytics Internship at CodTech\n",
        "\n",
        "Author : Rutuja Salve\n",
        "\n",
        "Internship Period : 6 Weeks (20th March 2025 to 05th May 2025)\n",
        "\n",
        "Domain : Data Analytics\n",
        "\n",
        "Task: Big Data Analysis on Airline Dataset\n",
        "Use the Airline Delay Dataset to perform big data analysis using tools like PySpark or Dask. The goal is to demonstrate scalability and derive meaningful insights from a large dataset.\n",
        "\n",
        "The dataset contains information about individual flights, such as the airline, origin, destination, scheduled departure time, actual departure time, and whether or not the flight was delayed."
      ],
      "metadata": {
        "id": "xi_296rgZNvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the Dataset"
      ],
      "metadata": {
        "id": "xukVQT0HZU14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark Example:"
      ],
      "metadata": {
        "id": "S58qnm_qaHp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Airline Delay Prediction\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "df = spark.read.csv(\"/content/Airline_Dataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the schema and first few rows\n",
        "df.printSchema()\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcRImdMDZMGy",
        "outputId": "28955047-cd2a-48ca-ad63-38925c9975c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- FL_DATE: date (nullable = true)\n",
            " |-- OP_CARRIER: string (nullable = true)\n",
            " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
            " |-- ORIGIN: string (nullable = true)\n",
            " |-- DEST: string (nullable = true)\n",
            " |-- CRS_DEP_TIME: integer (nullable = true)\n",
            " |-- DEP_TIME: double (nullable = true)\n",
            " |-- DEP_DELAY: double (nullable = true)\n",
            " |-- TAXI_OUT: double (nullable = true)\n",
            " |-- WHEELS_OFF: double (nullable = true)\n",
            " |-- WHEELS_ON: double (nullable = true)\n",
            " |-- TAXI_IN: double (nullable = true)\n",
            " |-- CRS_ARR_TIME: integer (nullable = true)\n",
            " |-- ARR_TIME: double (nullable = true)\n",
            " |-- ARR_DELAY: double (nullable = true)\n",
            " |-- CANCELLED: double (nullable = true)\n",
            " |-- CANCELLATION_CODE: string (nullable = true)\n",
            " |-- DIVERTED: double (nullable = true)\n",
            " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
            " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
            " |-- AIR_TIME: double (nullable = true)\n",
            " |-- DISTANCE: double (nullable = true)\n",
            " |-- CARRIER_DELAY: double (nullable = true)\n",
            " |-- WEATHER_DELAY: double (nullable = true)\n",
            " |-- NAS_DELAY: double (nullable = true)\n",
            " |-- SECURITY_DELAY: double (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
            " |-- Unnamed: 27: string (nullable = true)\n",
            "\n",
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
            "|2018-01-01|        UA|             2429|   EWR| DEN|        1517|  1512.0|     -5.0|    15.0|    1527.0|   1712.0|   10.0|        1745|  1722.0|    -23.0|      0.0|             NULL|     0.0|           268.0|              250.0|   225.0|  1605.0|         NULL|         NULL|     NULL|          NULL|               NULL|       NULL|\n",
            "|2018-01-01|        UA|             2427|   LAS| SFO|        1115|  1107.0|     -8.0|    11.0|    1118.0|   1223.0|    7.0|        1254|  1230.0|    -24.0|      0.0|             NULL|     0.0|            99.0|               83.0|    65.0|   414.0|         NULL|         NULL|     NULL|          NULL|               NULL|       NULL|\n",
            "|2018-01-01|        UA|             2426|   SNA| DEN|        1335|  1330.0|     -5.0|    15.0|    1345.0|   1631.0|    5.0|        1649|  1636.0|    -13.0|      0.0|             NULL|     0.0|           134.0|              126.0|   106.0|   846.0|         NULL|         NULL|     NULL|          NULL|               NULL|       NULL|\n",
            "|2018-01-01|        UA|             2425|   RSW| ORD|        1546|  1552.0|      6.0|    19.0|    1611.0|   1748.0|    6.0|        1756|  1754.0|     -2.0|      0.0|             NULL|     0.0|           190.0|              182.0|   157.0|  1120.0|         NULL|         NULL|     NULL|          NULL|               NULL|       NULL|\n",
            "|2018-01-01|        UA|             2424|   ORD| ALB|         630|   650.0|     20.0|    13.0|     703.0|    926.0|   10.0|         922|   936.0|     14.0|      0.0|             NULL|     0.0|           112.0|              106.0|    83.0|   723.0|         NULL|         NULL|     NULL|          NULL|               NULL|       NULL|\n",
            "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dask Example:"
      ],
      "metadata": {
        "id": "3uqtxxC2aQSA"
      }
    },
    {
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "# Define the data types for problematic columns, including CRS_ARR_TIME and CRS_DEP_TIME\n",
        "dtypes = {\n",
        "    'CANCELLATION_CODE': 'object',  # Specify as string/object type\n",
        "    'DEP_DELAY': 'float64',         # Example: Ensure numeric columns are correctly typed\n",
        "    'ARR_DELAY': 'float64',         # Example: Ensure numeric columns are correctly typed\n",
        "    'CRS_ARR_TIME': 'float64',     # Specify as float64 to accommodate potential variations\n",
        "    'CRS_DEP_TIME': 'float64',     # Specify as float64 to accommodate potential variations\n",
        "}\n",
        "\n",
        "# Load the dataset with specified dtypes\n",
        "df = dd.read_csv(\"/content/Airline_Dataset.csv\", dtype=dtypes)\n",
        "\n",
        "# Show the first few rows\n",
        "print(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znusvM8Abczf",
        "outputId": "b2a051da-8ab2-4541-a94b-3f444f6cf2d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
            "0  2018-01-01         UA               2429    EWR  DEN        1517.0   \n",
            "1  2018-01-01         UA               2427    LAS  SFO        1115.0   \n",
            "2  2018-01-01         UA               2426    SNA  DEN        1335.0   \n",
            "3  2018-01-01         UA               2425    RSW  ORD        1546.0   \n",
            "4  2018-01-01         UA               2424    ORD  ALB         630.0   \n",
            "\n",
            "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  CRS_ELAPSED_TIME  \\\n",
            "0    1512.0       -5.0      15.0      1527.0  ...             268.0   \n",
            "1    1107.0       -8.0      11.0      1118.0  ...              99.0   \n",
            "2    1330.0       -5.0      15.0      1345.0  ...             134.0   \n",
            "3    1552.0        6.0      19.0      1611.0  ...             190.0   \n",
            "4     650.0       20.0      13.0       703.0  ...             112.0   \n",
            "\n",
            "   ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
            "0                250.0     225.0    1605.0            NaN            NaN   \n",
            "1                 83.0      65.0     414.0            NaN            NaN   \n",
            "2                126.0     106.0     846.0            NaN            NaN   \n",
            "3                182.0     157.0    1120.0            NaN            NaN   \n",
            "4                106.0      83.0     723.0            NaN            NaN   \n",
            "\n",
            "  NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  \n",
            "0       NaN             NaN                  NaN          NaN  \n",
            "1       NaN             NaN                  NaN          NaN  \n",
            "2       NaN             NaN                  NaN          NaN  \n",
            "3       NaN             NaN                  NaN          NaN  \n",
            "4       NaN             NaN                  NaN          NaN  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform Data Cleaning\n",
        "\n",
        "Handle missing values.\n",
        "\n",
        "Drop unnecessary columns.\n",
        "\n",
        "Create a target variable for prediction (e.g., Delayed = 1 if DepDelay > 15 minutes, else 0)."
      ],
      "metadata": {
        "id": "hImufgycajbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark Example:"
      ],
      "metadata": {
        "id": "gcSNruNwcvmr"
      }
    },
    {
      "source": [
        "# Drop rows with missing values in 'DEP_DELAY'\n",
        "df = df.dropna(subset=[\"DEP_DELAY\"]) # Changed 'DepDelay' to 'DEP_DELAY'\n",
        "\n",
        "# Create target variable 'Delayed'\n",
        "# Since you are working with Dask, you need to use dask's way to create a new column\n",
        "df['Delayed'] = df['DEP_DELAY'].apply(lambda x: 1 if x > 15 else 0, meta=('Delayed', 'int64'))\n",
        "\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop([\"CANCELLATION_CODE\", \"DIVERTED\", \"ARR_DELAY\", \"ARR_TIME\", \"FL_DATE\"], axis=1)  # Dask drop uses axis=1 for columns\n",
        "\n",
        "# Show the cleaned dataset\n",
        "print(df.head()) # Dask uses .head() to display the first few rows"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1i4MjpjcEdP",
        "outputId": "cdac3c3d-90e3-40f9-d51b-3ec9598340f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  DEP_TIME  \\\n",
            "0         UA               2429    EWR  DEN        1517.0    1512.0   \n",
            "1         UA               2427    LAS  SFO        1115.0    1107.0   \n",
            "2         UA               2426    SNA  DEN        1335.0    1330.0   \n",
            "3         UA               2425    RSW  ORD        1546.0    1552.0   \n",
            "4         UA               2424    ORD  ALB         630.0     650.0   \n",
            "\n",
            "   DEP_DELAY  TAXI_OUT  WHEELS_OFF  WHEELS_ON  ...  ACTUAL_ELAPSED_TIME  \\\n",
            "0       -5.0      15.0      1527.0     1712.0  ...                250.0   \n",
            "1       -8.0      11.0      1118.0     1223.0  ...                 83.0   \n",
            "2       -5.0      15.0      1345.0     1631.0  ...                126.0   \n",
            "3        6.0      19.0      1611.0     1748.0  ...                182.0   \n",
            "4       20.0      13.0       703.0      926.0  ...                106.0   \n",
            "\n",
            "   AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  \\\n",
            "0     225.0    1605.0            NaN            NaN        NaN   \n",
            "1      65.0     414.0            NaN            NaN        NaN   \n",
            "2     106.0     846.0            NaN            NaN        NaN   \n",
            "3     157.0    1120.0            NaN            NaN        NaN   \n",
            "4      83.0     723.0            NaN            NaN        NaN   \n",
            "\n",
            "   SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  Delayed  \n",
            "0             NaN                  NaN          NaN        0  \n",
            "1             NaN                  NaN          NaN        0  \n",
            "2             NaN                  NaN          NaN        0  \n",
            "3             NaN                  NaN          NaN        0  \n",
            "4             NaN                  NaN          NaN        1  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engineering\n",
        "Encode categorical variables (e.g., UniqueCarrier, Origin, Dest).\n",
        "\n",
        "Normalize numerical features (e.g., Distance, CRSDepTime)."
      ],
      "metadata": {
        "id": "mDNiBOD9droB"
      }
    },
    {
      "source": [
        "# Drop rows with missing values in 'DEP_DELAY'\n",
        "df = df.dropna(subset=[\"DEP_DELAY\"]) # Changed 'DepDelay' to 'DEP_DELAY'\n",
        "\n",
        "# Create target variable 'Delayed'\n",
        "# Since you are working with Dask, you need to use dask's way to create a new column\n",
        "df['Delayed'] = df['DEP_DELAY'].apply(lambda x: 1 if x > 15 else 0, meta=('Delayed', 'int64'))\n",
        "\n",
        "# *** Comment out or remove the line dropping unnecessary columns to keep 'UniqueCarrier', 'Origin', 'Dest' ***\n",
        "# df = df.drop([\"CANCELLATION_CODE\", \"DIVERTED\", \"ARR_DELAY\", \"ARR_TIME\", \"FL_DATE\"], axis=1)  # Dask drop uses axis=1 for columns\n",
        "\n",
        "# Show the cleaned dataset\n",
        "print(df.head()) # Dask uses .head() to display the first few rows"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNEecdbPfJdI",
        "outputId": "3804acee-064a-4570-d040-21554a9b1c51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
            "0  2018-01-01         UA               2429    EWR  DEN        1517.0   \n",
            "1  2018-01-01         UA               2427    LAS  SFO        1115.0   \n",
            "2  2018-01-01         UA               2426    SNA  DEN        1335.0   \n",
            "3  2018-01-01         UA               2425    RSW  ORD        1546.0   \n",
            "4  2018-01-01         UA               2424    ORD  ALB         630.0   \n",
            "\n",
            "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  ACTUAL_ELAPSED_TIME  \\\n",
            "0    1512.0       -5.0      15.0      1527.0  ...                250.0   \n",
            "1    1107.0       -8.0      11.0      1118.0  ...                 83.0   \n",
            "2    1330.0       -5.0      15.0      1345.0  ...                126.0   \n",
            "3    1552.0        6.0      19.0      1611.0  ...                182.0   \n",
            "4     650.0       20.0      13.0       703.0  ...                106.0   \n",
            "\n",
            "   AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY SECURITY_DELAY  \\\n",
            "0     225.0    1605.0            NaN            NaN        NaN            NaN   \n",
            "1      65.0     414.0            NaN            NaN        NaN            NaN   \n",
            "2     106.0     846.0            NaN            NaN        NaN            NaN   \n",
            "3     157.0    1120.0            NaN            NaN        NaN            NaN   \n",
            "4      83.0     723.0            NaN            NaN        NaN            NaN   \n",
            "\n",
            "   LATE_AIRCRAFT_DELAY  Unnamed: 27  Delayed  \n",
            "0                  NaN          NaN        0  \n",
            "1                  NaN          NaN        0  \n",
            "2                  NaN          NaN        0  \n",
            "3                  NaN          NaN        0  \n",
            "4                  NaN          NaN        1  \n",
            "\n",
            "[5 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the Dataset\n",
        "Split the data into training and testing sets."
      ],
      "metadata": {
        "id": "6eqXJZiUfnKC"
      }
    },
    {
      "source": [
        "train_data, test_data = df.random_split([0.8, 0.2], random_state=42) # Changed 'seed' to 'random_state' to match Dask API"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fvCKXLsPfzhq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Train the Model\n",
        "Use a machine learning algorithm (e.g., Logistic Regression, Random Forest)."
      ],
      "metadata": {
        "id": "03bIjrnKf7i5"
      }
    },
    {
      "source": [
        "!pip install dask-ml\n",
        "import dask.dataframe as dd\n",
        "from dask_ml.linear_model import LogisticRegression\n",
        "from dask_ml.model_selection import train_test_split\n",
        "\n",
        "# ... (your data loading and preprocessing code) ...\n",
        "\n",
        "# Split the dataset using Dask-ML\n",
        "X = df[['CRS_DEP_TIME', 'DEP_DELAY', 'DISTANCE']] # Assuming these are your features\n",
        "y = df['Delayed']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert Dask DataFrames to Dask Arrays\n",
        "# **Fix:** Ensure that y_train and y_test are also converted to Dask Arrays\n",
        "X_train = X_train.to_dask_array(lengths=True)\n",
        "X_test = X_test.to_dask_array(lengths=True)\n",
        "y_train = y_train.to_dask_array(lengths=True)  # Convert y_train to Dask Array\n",
        "y_test = y_test.to_dask_array(lengths=True)  # Convert y_test to Dask Array\n",
        "\n",
        "\n",
        "# Build and train the model using Dask-ML\n",
        "lr = LogisticRegression()\n",
        "model = lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "# ... (evaluate the predictions using Dask-ML metrics) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3qQdkmsgwD4",
        "outputId": "e2f780e7-5d35-4aa6-b45e-b2b49482ee16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask-ml in /usr/local/lib/python3.11/dist-packages (2025.1.0)\n",
            "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (0.3.2)\n",
            "Requirement already satisfied: dask>=2025.1.0 in /usr/local/lib/python3.11/dist-packages (from dask[array,dataframe]>=2025.1.0->dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: distributed>=2025.1.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.0.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from dask-ml) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.14.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (8.6.1)\n",
            "Requirement already satisfied: sparse>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from dask-glm>=0.2.0->dask-ml) (0.15.5)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask[array,dataframe]>=2025.1.0->dask-ml) (18.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.1.6)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (2.3.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->dask-ml) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->dask-ml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->dask-ml) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed>=2025.1.0->dask-ml) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask-ml) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask_ml/model_selection/_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Evaluate the Model\n",
        "Calculate metrics like accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "ZGGpXYpGhue7"
      }
    },
    {
      "source": [
        "!pip install dask-ml\n",
        "import dask.dataframe as dd\n",
        "from dask_ml.linear_model import LogisticRegression\n",
        "from dask_ml.model_selection import train_test_split\n",
        "from dask_ml.metrics import accuracy_score # Import accuracy_score from dask_ml.metrics\n",
        "\n",
        "# ... (your data loading and preprocessing code) ...\n",
        "\n",
        "# Split the dataset using Dask-ML\n",
        "X = df[['CRS_DEP_TIME', 'DEP_DELAY', 'DISTANCE']] # Assuming these are your features\n",
        "y = df['Delayed']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert Dask DataFrames to Dask Arrays\n",
        "X_train = X_train.to_dask_array(lengths=True)\n",
        "X_test = X_test.to_dask_array(lengths=True)\n",
        "y_train = y_train.to_dask_array(lengths=True)  # Convert y_train to Dask Array\n",
        "y_test = y_test.to_dask_array(lengths=True)  # Convert y_test to Dask Array\n",
        "\n",
        "# Build and train the model using Dask-ML\n",
        "lr = LogisticRegression()\n",
        "model = lr.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy using Dask-ML's accuracy_score\n",
        "accuracy = accuracy_score(y_test, predictions)  # Use dask_ml.metrics.accuracy_score\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHlCQuaDh9XB",
        "outputId": "366c2534-959f-47ee-e999-fe2b4f8bd0b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask-ml in /usr/local/lib/python3.11/dist-packages (2025.1.0)\n",
            "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (0.3.2)\n",
            "Requirement already satisfied: dask>=2025.1.0 in /usr/local/lib/python3.11/dist-packages (from dask[array,dataframe]>=2025.1.0->dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: distributed>=2025.1.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.0.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from dask-ml) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from dask-ml) (1.14.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (2025.3.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (8.6.1)\n",
            "Requirement already satisfied: sparse>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from dask-glm>=0.2.0->dask-ml) (0.15.5)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask[array,dataframe]>=2025.1.0->dask-ml) (18.1.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.1.6)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (6.4.2)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (2.3.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed>=2025.1.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->dask-ml) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask-ml) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->dask-ml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.1->dask-ml) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2025.1.0->dask[array,dataframe]>=2025.1.0->dask-ml) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.10.3->distributed>=2025.1.0->dask-ml) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask-ml) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask_ml/model_selection/_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wUoL6cYh-A8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}